[{"categories":[],"content":"Hugo测试 标题 1# 一级标题 2 3## 二级标题 4 5### 三级标题 6 7#### 四级标题 表格    1 1 1     2 2 2   3 3 3   4 4 4    代码抄录环境 1int main() 2{ 3\treturn 0; 4} 流程图 1graph TD; 2 A--\u0026gt;B; 3 A--\u0026gt;C; 4 B--\u0026gt;D; 5 C--\u0026gt;D; 数学公式 $$x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}$$\n","date":"Sep 25, 2021","img":"","permalink":"https://mengdemao.github.io/posts/hugo%E6%B5%8B%E8%AF%95/","series":null,"tags":[],"title":"Hugo测试"},{"categories":null,"content":"LuaJIT Lua语法 基本语法 1\tprint(\u0026#34;Hello World\u0026#34;) 表(table) LuaJIT分析 LuaJIT主函数 1int main(int argc, char **argv) 2{ 3\tint status; /* 返回值 */ 4\tlua_State *L = lua_open(); /* 创建LUA状态机 */ 5\tif (L == NULL) { 6\tl_message(argv[0], \u0026#34;cannot create state: not enough memory\u0026#34;); 7\treturn EXIT_FAILURE; 8\t} 9\t10\t/* smain只存在三个参数,主要作用是向pmain传递数据 */ 11\tsmain.argc = argc; 12\tsmain.argv = argv; 13\t14\tstatus = lua_cpcall(L, pmain, NULL);\t/* 启动函数调用 */ 15\t16\treport(L, status); /* 提取报错参数 */ 17\t18\tlua_close(L);\t/* 销毁状态机 */ 19\t20\treturn (status || smain.status \u0026gt; 0) ? EXIT_FAILURE : EXIT_SUCCESS; 21} Lua状态机 1struct lua_State { 2\tGCObject*next; 3 4 lu_byte tt; 5 lu_byte marked; 6\tlu_byte status; 7\t8 StkId top; 9\tStkId base; 10\t11 global_State *l_G;\t/* 全局状态信息 */ 12\t13 CallInfo*ci; 14\t15 const Instruction*savedpc; 16\tStkId stack_last; 17\tStkId stack; 18\t19 CallInfo*end_ci; 20\tCallInfo*base_ci; 21\t22 int stacksize; 23\tint size_ci; 24\tunsigned short nCcalls; 25\tunsigned short baseCcalls; 26\t27 lu_byte hookmask; 28\tlu_byte allowhook; 29\t30 int basehookcount; 31\tint hookcount; 32\t33 lua_Hook hook; 34\t35 TValue l_gt; 36\tTValue env; 37\t38 GCObject*openupval; 39\tGCObject*gclist; 40\t41 struct lua_longjmp*errorJmp; 42\t43 ptrdiff_t errfunc; 44}; 创建状态 1/* 此函数实际不存在,程序内部使用的是宏定义 */ 2void lua_open(void); 3 4/* 实际调用位置 */ 5LUALIB_API lua_State *luaL_newstate(void); 6 7/* 根据编译期64位信息选择调用 */ 8#if LJ_64 \u0026amp;\u0026amp; !LJ_GC64 \u0026amp;\u0026amp; !(defined(LUAJIT_USE_VALGRIND) \u0026amp;\u0026amp; defined(LUAJIT_USE_SYSMALLOC)) 9lua_State *lj_state_newstate(lua_Alloc allocf, void *allocd); 10#else 11LUA_API lua_State *lua_newstate(lua_Alloc allocf, void *allocd); 12#endif 函数调用 1LUA_API int lua_cpcall(lua_State *L, lua_CFunction func, void *ud); 2LUA_API int lua_pcall(lua_State *L, int nargs, int nresults, int errfunc); 3LUA_API void lua_call(lua_State *L, int nargs, int nresults); lua_cpcall函数调用\n执行原理 FFI分析 ","date":"Sep 4, 2021","img":"","permalink":"https://mengdemao.github.io/posts/luajit/","series":null,"tags":null,"title":"LuaJIT"},{"categories":null,"content":"编译原理 基础概念 词法分析 RE NFA DFA 语法分析 上下文无关文法(CFG) 自上而下(Top Down) 自下而上(Bottom Up) 语义分析 中间代码 目标代码 ","date":"Sep 4, 2021","img":"","permalink":"https://mengdemao.github.io/posts/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/","series":null,"tags":null,"title":"编译原理"},{"categories":null,"content":"页面分配器 核心函数: __alloc_pages_nodemask\n gfp_mask : 分配掩码 order : 分配阶数 preferred_nid nodemask  核心函数 1struct page *__alloc_pages_nodemask(gfp_t gfp_mask, unsigned int order, int preferred_nid, nodemask_t *nodemask) 2{ 3\tstruct page *page;\t// 分配变量 4\tunsigned int alloc_flags = ALLOC_WMARK_LOW;\t// 分配标志 5\tgfp_t alloc_mask; // 真实分配掩码 6\tstruct alloc_context ac = { };\t// 保存相关参数 7 8\t/* 9* There are several places where we assume that the order value is sane 10* so bail out early if the request is out of bound. 11* 限制分配的大小 12*/ 13\tif (unlikely(order \u0026gt;= MAX_ORDER)) { 14\tWARN_ON_ONCE(!(gfp_mask \u0026amp; __GFP_NOWARN)); 15\treturn NULL; 16\t} 17 18\tgfp_mask \u0026amp;= gfp_allowed_mask; 19\talloc_mask = gfp_mask; 20\tif (!prepare_alloc_pages(gfp_mask, order, preferred_nid, nodemask, \u0026amp;ac, \u0026amp;alloc_mask, \u0026amp;alloc_flags)) 21\treturn NULL; 22 23\tfinalise_ac(gfp_mask, \u0026amp;ac); 24 25\t/* First allocation attempt */ 26\tpage = get_page_from_freelist(alloc_mask, order, alloc_flags, \u0026amp;ac); 27\tif (likely(page)) 28\tgoto out; 29 30\t/* 31* Apply scoped allocation constraints. This is mainly about GFP_NOFS 32* resp. GFP_NOIO which has to be inherited for all allocation requests 33* from a particular context which has been marked by 34* memalloc_no{fs,io}_{save,restore}. 35*/ 36\talloc_mask = current_gfp_context(gfp_mask); 37\tac.spread_dirty_pages = false; 38 39\t/* 40* Restore the original nodemask if it was potentially replaced with 41* \u0026amp;cpuset_current_mems_allowed to optimize the fast-path attempt. 42*/ 43\tif (unlikely(ac.nodemask != nodemask)) 44\tac.nodemask = nodemask; 45 46\tpage = __alloc_pages_slowpath(alloc_mask, order, \u0026amp;ac); 47 48out: 49\tif (memcg_kmem_enabled() \u0026amp;\u0026amp; (gfp_mask \u0026amp; __GFP_ACCOUNT) \u0026amp;\u0026amp; page \u0026amp;\u0026amp; 50\tunlikely(memcg_kmem_charge(page, gfp_mask, order) != 0)) { 51\t__free_pages(page, order); 52\tpage = NULL; 53\t} 54 55\ttrace_mm_page_alloc(page, order, alloc_mask, ac.migratetype); 56 57\treturn page; 58} prepare_alloc_pages 1static inline bool prepare_alloc_pages(gfp_t gfp_mask, unsigned int order, 2\tint preferred_nid, nodemask_t *nodemask, 3\tstruct alloc_context *ac, gfp_t *alloc_mask, 4\tunsigned int *alloc_flags) 5{ 6\tac-\u0026gt;high_zoneidx = gfp_zone(gfp_mask); 7\tac-\u0026gt;zonelist = node_zonelist(preferred_nid, gfp_mask); 8\tac-\u0026gt;nodemask = nodemask; 9\tac-\u0026gt;migratetype = gfpflags_to_migratetype(gfp_mask); 10 11\tif (cpusets_enabled()) { 12\t*alloc_mask |= __GFP_HARDWALL; 13\tif (!ac-\u0026gt;nodemask) 14\tac-\u0026gt;nodemask = \u0026amp;cpuset_current_mems_allowed; 15\telse 16\t*alloc_flags |= ALLOC_CPUSET; 17\t} 18 19\tfs_reclaim_acquire(gfp_mask); 20\tfs_reclaim_release(gfp_mask); 21 22\tmight_sleep_if(gfp_mask \u0026amp; __GFP_DIRECT_RECLAIM); 23 24\tif (should_fail_alloc_page(gfp_mask, order)) 25\treturn false; 26 27\tif (IS_ENABLED(CONFIG_CMA) \u0026amp;\u0026amp; ac-\u0026gt;migratetype == MIGRATE_MOVABLE) 28\t*alloc_flags |= ALLOC_CMA; 29 30\treturn true; 31} get_page_from_freelist 1static struct page * 2get_page_from_freelist(gfp_t gfp_mask, unsigned int order, int alloc_flags, 3\tconst struct alloc_context *ac) 4{ 5\tstruct zoneref *z = ac-\u0026gt;preferred_zoneref; 6\tstruct zone *zone; 7\tstruct pglist_data *last_pgdat_dirty_limit = NULL; 8 9\t/* 10* Scan zonelist, looking for a zone with enough free. 11* See also __cpuset_node_allowed() comment in kernel/cpuset.c. 12*/ 13\tfor_next_zone_zonelist_nodemask(zone, z, ac-\u0026gt;zonelist, ac-\u0026gt;high_zoneidx, 14\tac-\u0026gt;nodemask) { 15\tstruct page *page; 16\tunsigned long mark; 17 18\tif (cpusets_enabled() \u0026amp;\u0026amp; 19\t(alloc_flags \u0026amp; ALLOC_CPUSET) \u0026amp;\u0026amp; 20\t!__cpuset_zone_allowed(zone, gfp_mask)) 21\tcontinue; 22\t/* 23* When allocating a page cache page for writing, we 24* want to get it from a node that is within its dirty 25* limit, such that no single node holds more than its 26* proportional share of globally allowed dirty pages. 27* The dirty limits take into account the node\u0026#39;s 28* lowmem reserves and high watermark so that kswapd 29* should be able to balance it without having to 30* write pages from its LRU list. 31* 32* XXX: For now, allow allocations to potentially 33* exceed the per-node dirty limit in the slowpath 34* (spread_dirty_pages unset) before going into reclaim, 35* which is important when on a NUMA setup the allowed 36* nodes are together not big enough to reach the 37* global limit. The proper fix for these situations 38* will require awareness of nodes in the 39* dirty-throttling and the flusher threads. 40*/ 41\tif (ac-\u0026gt;spread_dirty_pages) { 42\tif (last_pgdat_dirty_limit == zone-\u0026gt;zone_pgdat) 43\tcontinue; 44 45\tif (!node_dirty_ok(zone-\u0026gt;zone_pgdat)) { 46\tlast_pgdat_dirty_limit = zone-\u0026gt;zone_pgdat; 47\tcontinue; 48\t} 49\t} 50 51\tmark = zone-\u0026gt;watermark[alloc_flags \u0026amp; ALLOC_WMARK_MASK]; 52\tif (!zone_watermark_fast(zone, order, mark, 53\tac_classzone_idx(ac), alloc_flags)) { 54\tint ret; 55 56#ifdef CONFIG_DEFERRED_STRUCT_PAGE_INIT 57\t/* 58* Watermark failed for this zone, but see if we can 59* grow this zone if it contains deferred pages. 60*/ 61\tif (static_branch_unlikely(\u0026amp;deferred_pages)) { 62\tif (_deferred_grow_zone(zone, order)) 63\tgoto try_this_zone; 64\t} 65#endif 66\t/* Checked here to keep the fast path fast */ 67\tBUILD_BUG_ON(ALLOC_NO_WATERMARKS \u0026lt; NR_WMARK); 68\tif (alloc_flags \u0026amp; ALLOC_NO_WATERMARKS) 69\tgoto try_this_zone; 70 71\tif (node_reclaim_mode == 0 || 72\t!zone_allows_reclaim(ac-\u0026gt;preferred_zoneref-\u0026gt;zone, zone)) 73\tcontinue; 74 75\tret = node_reclaim(zone-\u0026gt;zone_pgdat, gfp_mask, order); 76\tswitch (ret) { 77\tcase NODE_RECLAIM_NOSCAN: 78\t/* did not scan */ 79\tcontinue; 80\tcase NODE_RECLAIM_FULL: 81\t/* scanned but unreclaimable */ 82\tcontinue; 83\tdefault: 84\t/* did we reclaim enough */ 85\tif (zone_watermark_ok(zone, order, mark, 86\tac_classzone_idx(ac), alloc_flags)) 87\tgoto try_this_zone; 88 89\tcontinue; 90\t} 91\t} 92 93try_this_zone: 94\tpage = rmqueue(ac-\u0026gt;preferred_zoneref-\u0026gt;zone, zone, order, 95\tgfp_mask, alloc_flags, ac-\u0026gt;migratetype); 96\tif (page) { 97\tprep_new_page(page, order, gfp_mask, alloc_flags); 98 99\t/* 100* If this is a high-order atomic allocation then check 101* if the pageblock should be reserved for the future 102*/ 103\tif (unlikely(order \u0026amp;\u0026amp; (alloc_flags \u0026amp; ALLOC_HARDER))) 104\treserve_highatomic_pageblock(page, zone, order); 105 106\treturn page; 107\t} else { 108#ifdef CONFIG_DEFERRED_STRUCT_PAGE_INIT 109\t/* Try again if zone has deferred pages */ 110\tif (static_branch_unlikely(\u0026amp;deferred_pages)) { 111\tif (_deferred_grow_zone(zone, order)) 112\tgoto try_this_zone; 113\t} 114#endif 115\t} 116\t} 117 118\treturn NULL; 119} ","date":"May 9, 2021","img":"","permalink":"https://mengdemao.github.io/posts/page_allocator/","series":null,"tags":null,"title":"Page_allocator"},{"categories":null,"content":"等待事件是建立在调度的基础之上的一种同步机制\n使用 等待队列头 1struct __wait_queue_head { 2\twq_lock_t lock; 3\tstruct list_head task_list; 4}; 5typedef struct __wait_queue_head wait_queue_head_t; 等待队列实体 1struct __wait_queue { 2\tunsigned int flags; 3\tstruct task_struct * task; 4\tstruct list_head task_list; 5}; 6typedef struct __wait_queue wait_queue_t; 初始化等待队列头 1void __init_waitqueue_head(struct wait_queue_head *wq_head, 2\tconst char *name, struct lock_class_key *); 3void init_waitqueue_head(struct wait_queue_head *wq_head); 初始化等待队列 1#define __WAITQUEUE_INITIALIZER(name, tsk) \\ 2{\t\\ 3.private\t= tsk,\t\\ 4.func\t= default_wake_function,\t\\ 5.entry\t= { NULL, NULL }\t\\ 6} 7 8#define DECLARE_WAITQUEUE(name, tsk) struct wait_queue_entry name = __WAITQUEUE_INITIALIZER(name, tsk) 9 10// 但是，一般直接 11DECLARE_WAITQUEUE(wait, current);  等待队列入口 等待的任务  等待队列操作 1void add_wait_queue(struct wait_queue_head *wq_head, 2\tstruct wait_queue_entry *wq_entry); 3void remove_wait_queue(struct wait_queue_head *wq_head, 4\tstruct wait_queue_entry *wq_entry);  等待队列头 等待队列实体  等待事件 1void wait_event(wq, condition); 2void wait_event_interruptible(wq, condition); 唤醒队列  wake_up wake_up_all wake_up_interruptible wake_up_interruptible_all wake_up_sync wake_up_interruptible_sync  例子 写端 1ssize_t wait_write(struct file *file, const char __user *data, size_t len, loff_t *ppos) 2{ 3\tDECLARE_WAITQUEUE(wait, current);\t/* 声明等待队列 */ 4\tint ret = -1; 5\tPTRACE; 6 7\tmutex_lock(\u0026amp;wait_device.mutex); 8\t/* 非阻塞模式直接写入 */ 9\tif (file-\u0026gt;f_flags \u0026amp; O_NONBLOCK) { 10\tpr_err(\u0026#34;write in O_NONBLOCK Mode\u0026#34;); 11\tgoto pure_write; 12\t} 13 14\tadd_wait_queue(\u0026amp;wait_device.wait_w, \u0026amp;wait); 15\twhile (wait_device.wait_flag == true) { 16\tpr_err(\u0026#34;Write INTERRUPTIBLE\u0026#34;); 17\t__set_current_state(TASK_INTERRUPTIBLE); 18\tmutex_unlock(\u0026amp;wait_device.mutex); 19\tschedule(); 20\tif (signal_pending(current)) { 21\tret = -ERESTARTSYS; 22\tremove_wait_queue(\u0026amp;wait_device.wait_w, \u0026amp;wait); 23\t__set_current_state(TASK_RUNNING); 24\tgoto out; 25\t} 26\t} 27\tremove_wait_queue(\u0026amp;wait_device.wait_w, \u0026amp;wait); 28 29pure_write: 30\twait_device.wait_flag = true; 31\tpr_err(\u0026#34;Write Successful\u0026#34;); 32 33\twake_up_interruptible(\u0026amp;wait_device.wait_r); 34\tpr_err(\u0026#34;Wakeup Read\u0026#34;); 35\tgoto out; 36 37out: 38\tmutex_unlock(\u0026amp;wait_device.mutex); 39\treturn ret; 40} 读端 1 ssize_t wait_read(struct file *file, char __user *buf, size_t len, loff_t * ppos) 2{ 3\tDECLARE_WAITQUEUE(wait, current);\t/* 声明等待队列 */ 4\tint ret = 0; 5\tPTRACE; 6 7\tmutex_lock(\u0026amp;wait_device.mutex); 8\t/* 非阻塞模式直接写入 */ 9\tif (file-\u0026gt;f_flags \u0026amp; O_NONBLOCK) { 10\tpr_err(\u0026#34;write in O_NONBLOCK Mode\u0026#34;); 11\tgoto pure_read; 12\t} 13 14\tadd_wait_queue(\u0026amp;wait_device.wait_r, \u0026amp;wait); 15\twhile (wait_device.wait_flag == false) { 16\tpr_err(\u0026#34;Write INTERRUPTIBLE\u0026#34;); 17\t__set_current_state(TASK_INTERRUPTIBLE); 18\tmutex_unlock(\u0026amp;wait_device.mutex); 19\tschedule(); 20\tif (signal_pending(current)) { 21\tret = -ERESTARTSYS; 22\tremove_wait_queue(\u0026amp;wait_device.wait_r, \u0026amp;wait); 23\t__set_current_state(TASK_RUNNING); 24\tgoto out; 25\t} 26\t} 27\tremove_wait_queue(\u0026amp;wait_device.wait_r, \u0026amp;wait); 28 29pure_read: 30\twait_device.wait_flag = false; 31\tpr_err(\u0026#34;Read Successful\u0026#34;); 32 33\twake_up_interruptible(\u0026amp;wait_device.wait_w); 34\tpr_err(\u0026#34;Wakeup Write\u0026#34;); 35 36\tgoto out; 37 38out: 39\tmutex_unlock(\u0026amp;wait_device.mutex); 40\treturn 0; 41} 原理 ","date":"May 4, 2021","img":"","permalink":"https://mengdemao.github.io/posts/wait_queue/","series":null,"tags":null,"title":"Linux等待队列实现"},{"categories":null,"content":"","date":"May 4, 2021","img":"","permalink":"https://mengdemao.github.io/posts/antlr/","series":null,"tags":["技巧"],"title":"Antlr教程"},{"categories":null,"content":" 初始化hugo  1hugo new site 路径  创建文档  1hugo new post/hugo.md  设置预览  1 hugo server -D ","date":"May 4, 2021","img":"","permalink":"https://mengdemao.github.io/posts/hugo/","series":null,"tags":["技巧"],"title":"Hugo使用教程"},{"categories":null,"content":"nfs服务 安装 1sudo apt-get install nfs-kernel-server 设置导出 1/home/exports *(rw,nohide,insecure,no_subtree_check,async,no_root_squash) 开启服务 1sudo /etc/init.d/nfs-kernel-server restart 测试 1sudo mount -t nfs -o nolock,vers=3 127.0.0.1:/home/exports /mnt 2ls /mnt ","date":"May 3, 2021","img":"","permalink":"https://mengdemao.github.io/posts/nfs/","series":null,"tags":["nfs"],"title":"Nfs"}]